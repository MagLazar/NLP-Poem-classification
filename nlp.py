# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wupECDVumInpMJ4_w1yX-kwcwW08W5I7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

train = pd.read_csv('/content/drive/MyDrive/Poem_classification - train_data.csv')
train.head()

test = pd.read_csv('/content/drive/MyDrive/Poem_classification - test_data.csv')
test.head()

train = train.dropna()
test = test.dropna()

train

sns.countplot(x = train["Genre"], palette='inferno')

sns.countplot(x = test["Genre"], palette='inferno')

test["Genre"] =test["Genre"].replace({'Music':0,'Death':1,'Affection':2,'Environment':3})
test

train["Genre"] =train["Genre"].replace({'Music':0,'Death':1,'Affection':2,'Environment':3})
train

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string

nltk.download('punkt')
nltk.download('stopwords')

def preprocess_text(text):

    tokens = word_tokenize(text)

    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word.lower() not in stop_words]

    tokens = [word for word in tokens if word.isalnum()]

    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]

    tokens = [word.lower() for word in tokens]

    return tokens

test['Poem_Processed'] = test['Poem'].apply(preprocess_text)
test

train['Poem_Processed'] = train['Poem'].apply(preprocess_text)
train

X_train = train['Poem_Processed']
y_train = train['Genre']

X_test = test['Poem_Processed']
y_test = test['Genre']

from sklearn.feature_extraction.text import TfidfVectorizer

X_train_str = [' '.join(tokens) for tokens in X_train]
X_test_str = [' '.join(tokens) for tokens in X_test]

tfidf_vectorizer = TfidfVectorizer()

X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_str)

X_test_tfidf = tfidf_vectorizer.transform(X_test_str)

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import SGDClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

clf1 = SGDClassifier()
clf2 = XGBClassifier()
clf3 = LogisticRegression()
clf4 = RandomForestClassifier()
clf5 = SVC()

eclf = VotingClassifier(estimators=[('SGD', clf1), ('XGB', clf2), ('LG', clf3),
                                    ('RC', clf4), ('SVC', clf5)], voting='hard')

def fit(classifier, X, y, scoring, cv):
    return cross_val_score(classifier, X, y, scoring=scoring, cv=cv)

for clf, label in zip([clf1, clf2, clf3, clf4, clf5, eclf],
                      ['SGD', 'XGB', 'LG', 'RC', 'SVC', 'Ensemble']):
    scores = fit(clf, X_train_tfidf, y_train, scoring='accuracy', cv=5)
    print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))

best_model = eclf.fit(X_train_tfidf, y_train)

predictions = best_model.predict(X_test_tfidf)

from sklearn.metrics import accuracy_score, classification_report

accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

print("\nClassification Report:\n", classification_report(y_test, predictions))

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, predictions)

category_mapping = {0: 'Music', 1: 'Death', 2: 'Affection', 3: 'Environment'}

cm_df = pd.DataFrame(cm, index=category_mapping.values(), columns=category_mapping.values())

plt.figure(figsize=(5, 5))
sns.heatmap(cm_df, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import seaborn as sns
plt.figure(figsize=(8, 6))
sns.countplot(x="Genre", data=train, palette='cubehelix')
plt.title("Distribution of Classes")
plt.xticks([0, 1, 2, 3], ['Music', 'Death', 'Affection', 'Environment'])
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10), sharey=True, sharex=True)

unique_categories = train['Genre'].unique()

for i, category in enumerate(unique_categories):
    row, col = i // 2, i % 2
    category_poems = train[train['Genre'] == category]['Poem_Processed']

    sns.histplot(category_poems.apply(len), ax=axes[row, col], kde=True)
    axes[row, col].set_title(f"Distribution of Poem Lengths - {category}")
    axes[row, col].set_xlabel("Poem Length")

plt.tight_layout()
plt.show()

from sklearn.manifold import TSNE

X_embedded = TSNE(n_components=2).fit_transform(X_train_tfidf.toarray())

plt.figure(figsize=(10, 8))
sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=y_train, palette="viridis")
plt.title("t-SNE Visualization of TF-IDF Vectors")
plt.show()

from wordcloud import WordCloud

category_mapping = {0: 'Music', 1: 'Death', 2: 'Affection', 3: 'Environment'}

unique_categories = train['Genre'].unique()

for selected_category in unique_categories:

    selected_category_poems = train[train['Genre'] == selected_category]['Poem_Processed']

    wordcloud = WordCloud(width=600, height=600,
                          background_color='white',
                          stopwords=set(stopwords.words('english')),
                          min_font_size=10).generate(' '.join(selected_category_poems.apply(' '.join)))

    plt.figure(figsize=(8, 8), facecolor=None)
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.tight_layout(pad=0)

    plt.title(f"Word Cloud for Category '{category_mapping[selected_category]}'")

    plt.show()